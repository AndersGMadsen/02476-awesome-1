{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torchvision import transforms\n",
    "from tests import _PATH_DATA\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from os import path, listdir\n",
    "import numpy as np\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dir):\n",
    "\n",
    "    idx_dict = {\n",
    "        'train': [\n",
    "            34, 101, 114, 82, 123, 57, 22, 15, 137, 83, 99, 72, 47,\n",
    "            36, 96, 46, 120, 60, 19, 79, 58, 134, 39, 102, 126, 94,\n",
    "            7, 106, 2, 40, 70, 52, 104, 12, 119, 76, 108, 90, 147,\n",
    "            143, 43, 140, 142, 88, 93, 4, 51, 16, 121, 74, 64, 77,\n",
    "            98, 107, 56, 13, 92, 3, 141, 136, 146, 78, 91, 35, 124,\n",
    "            63, 130, 84, 17, 80, 25, 118, 6, 113, 117, 67, 100, 54,\n",
    "            103, 95, 37, 23, 32, 30, 42, 144, 75, 38, 50, 31, 66,\n",
    "            131, 68, 97, 85, 44, 69, 33, 5, 138, 49, 14, 128, 24,\n",
    "            11, 89, 135, 10, 29, 116, 65, 18, 125, 20, 26, 111, 73,\n",
    "            48, 59, 139],\n",
    "        'validation': [86, 21, 55, 61, 45, 81, 105, 149, 27, 132, 28, 129, 1, 53, 133],\n",
    "        'test': [115, 109, 87, 112, 8, 9, 122, 41, 148, 110, 145, 71, 150, 127, 0, 62]\n",
    "    }\n",
    "\n",
    "    image_dir = dir+'/images'\n",
    "    mask_dir = dir+'/masks'\n",
    "\n",
    "    image_names = sorted([image for image in listdir(image_dir) if image.endswith('.png')])\n",
    "    \n",
    "    train_names = [image_names[idx] for idx in idx_dict['train']]\n",
    "    validation_names = [image_names[idx] for idx in idx_dict['validation']]\n",
    "    test_names = [image_names[idx] for idx in idx_dict['test']]\n",
    "\n",
    "    name_dict = {'train': train_names, 'validation': validation_names, 'test': test_names}\n",
    "\n",
    "    return name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = '../data/raw'\n",
    "name_dict = split_data(raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST DATA\n",
    "assert len(name_dict['train']) == 120, \"Train data did not have correct number of images\"\n",
    "assert len(name_dict['validation']) == 15, \"Train data did not have correct number of images\"\n",
    "assert len(name_dict['test']) == 16, \"Test data did not have correct number of images\"\n",
    "    \n",
    "#for name in name_dict['train']:\n",
    "#    image = torchvision.io.read_image(raw_dir+'/images/'+name)\n",
    "#    assert image.shape[]\n",
    "\n",
    "first_image = torchvision.io.read_image(raw_dir+'/images/'+name_dict['train'][0])\n",
    "assert first_image.shape[0] == 3, \"Fist image was not 3-dimensional\"\n",
    "\n",
    "image_names = sorted([image for image in listdir(raw_dir+'/images') if image.endswith('.png')])\n",
    "mask_names  = sorted([image for image in listdir(raw_dir+'/masks') if image.endswith('.png')])\n",
    "assert image_names == mask_names, \"Image names did not match mask names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slice_idxs(size, down_size):\n",
    "    height, width = size[:2]\n",
    "    down_height, down_width = down_size[:2]\n",
    "\n",
    "    n_images_height = height // down_height + 1\n",
    "    n_images_width = width // down_width + 1\n",
    "\n",
    "    offsets_height = np.concatenate(([0], np.diff(np.linspace(0,  n_images_height * down_height - height, n_images_height, dtype=int))))\n",
    "    offsets_height = np.cumsum(offsets_height).reshape(-1, 1)\n",
    "    offsets_width = np.concatenate(([0], np.diff(np.linspace(0,  n_images_width * down_width - width, n_images_width, dtype=int))))\n",
    "    offsets_width = np.cumsum(offsets_width).reshape(-1, 1)\n",
    "\n",
    "    idxs_height = np.arange(0, n_images_height)\n",
    "    idxs_height = np.concatenate((idxs_height, idxs_height+1))*down_height\n",
    "    idxs_height = idxs_height.reshape(-1, 2, order='F') - offsets_height\n",
    "\n",
    "    idxs_width = np.arange(0, n_images_width)\n",
    "    idxs_width = np.concatenate((idxs_width, idxs_width+1))*down_width\n",
    "    idxs_width = idxs_width.reshape(-1, 2, order='F') - offsets_width\n",
    "\n",
    "    return idxs_height, idxs_width\n",
    "\n",
    "def slice_image(image, size, idxs_height, idxs_width):\n",
    "    images = np.empty((len(idxs_height), len(idxs_width), *size))\n",
    "    for i, (sy, ey) in enumerate(idxs_height):\n",
    "        for j, (sx, ex) in enumerate(idxs_width):\n",
    "            images[i, j] = image[sy:ey, sx:ex]\n",
    "    return images\n",
    "\n",
    "def unslice_images(images, size, idxs_height, idxs_width, combine_func=lambda x: np.mean(x, axis=0)):\n",
    "    image = np.full((size), np.nan)\n",
    "    for i, (sy, ey) in enumerate(idxs_height):\n",
    "        for j, (sx, ex) in enumerate(idxs_width):\n",
    "            slice = image[sy:ey, sx:ex]\n",
    "            slice[np.isnan(slice)] = images[i, j, np.isnan(slice)]\n",
    "            slice[~np.isnan(slice)] = combine_func((slice[~np.isnan(slice)], images[i, j, ~np.isnan(slice)]))        \n",
    "    return image\n",
    "\n",
    "# unslice_images(slices, image.shape, idxs_height, idxs_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST PREPROCESS\n",
    "image = torch.moveaxis(torchvision.io.read_image(raw_dir+'/images/'+name_dict['train'][0]), 0, -1)\n",
    "\n",
    "slice_size = (512, 512)\n",
    "\n",
    "idxs_height, idxs_width = get_slice_idxs(image.shape, slice_size)\n",
    "image_slices = slice_image(image, slice_size + (3,), idxs_height, idxs_width)\n",
    "\n",
    "for i in range(image_slices.shape[0]):\n",
    "    for j in range(image_slices.shape[1]):\n",
    "        assert image_slices[i,j].shape == slice_size + (3,), \"Image slice did not have correct dimensions\"\n",
    "\n",
    "unsliced_image = unslice_images(image_slices, image.shape, idxs_height, idxs_width)\n",
    "assert unsliced_image.shape == image.shape, \"Unsliced image dimensions did not match original image\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc2d3b61f1e9e23e3b2650d02a265826715832c8045a8807a8a04cd462939354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
