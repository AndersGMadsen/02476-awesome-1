{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from tests import _PATH_DATA\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from os import path, listdir\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from src.data.dataset import BCSSDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = '../data/processed/'\n",
    "\n",
    "train_data = BCSSDataset(root_dir=raw_dir, key=\"train\")\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=1, shuffle=True, num_workers=6)\n",
    "image, mask = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('../data/processed/validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## TEST DATA\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(name_dict[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m120\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTrain data did not have correct number of images\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(name_dict[\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m15\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTrain data did not have correct number of images\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(name_dict[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m16\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTest data did not have correct number of images\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name_dict' is not defined"
     ]
    }
   ],
   "source": [
    "## TEST DATA\n",
    "assert len(name_dict['train']) == 120, \"Train data did not have correct number of images\"\n",
    "assert len(name_dict['validation']) == 15, \"Train data did not have correct number of images\"\n",
    "assert len(name_dict['test']) == 16, \"Test data did not have correct number of images\"\n",
    "    \n",
    "#for name in name_dict['train']:\n",
    "#    image = torchvision.io.read_image(raw_dir+'/images/'+name)\n",
    "#    assert image.shape[]\n",
    "\n",
    "first_image = torchvision.io.read_image(raw_dir+'/images/'+name_dict['train'][0])\n",
    "assert first_image.shape[0] == 3, \"Fist image was not 3-dimensional\"\n",
    "\n",
    "image_names = sorted([image for image in listdir(raw_dir+'/images') if image.endswith('.png')])\n",
    "mask_names  = sorted([image for image in listdir(raw_dir+'/masks') if image.endswith('.png')])\n",
    "assert image_names == mask_names, \"Image names did not match mask names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slice_idxs(size, down_size):\n",
    "    height, width = size[:2]\n",
    "    down_height, down_width = down_size[:2]\n",
    "\n",
    "    n_images_height = height // down_height + 1\n",
    "    n_images_width = width // down_width + 1\n",
    "\n",
    "    offsets_height = np.concatenate(([0], np.diff(np.linspace(0,  n_images_height * down_height - height, n_images_height, dtype=int))))\n",
    "    offsets_height = np.cumsum(offsets_height).reshape(-1, 1)\n",
    "    offsets_width = np.concatenate(([0], np.diff(np.linspace(0,  n_images_width * down_width - width, n_images_width, dtype=int))))\n",
    "    offsets_width = np.cumsum(offsets_width).reshape(-1, 1)\n",
    "\n",
    "    idxs_height = np.arange(0, n_images_height)\n",
    "    idxs_height = np.concatenate((idxs_height, idxs_height+1))*down_height\n",
    "    idxs_height = idxs_height.reshape(-1, 2, order='F') - offsets_height\n",
    "\n",
    "    idxs_width = np.arange(0, n_images_width)\n",
    "    idxs_width = np.concatenate((idxs_width, idxs_width+1))*down_width\n",
    "    idxs_width = idxs_width.reshape(-1, 2, order='F') - offsets_width\n",
    "\n",
    "    return idxs_height, idxs_width\n",
    "\n",
    "def slice_image(image, size, idxs_height, idxs_width):\n",
    "    images = np.empty((len(idxs_height), len(idxs_width), *size))\n",
    "    for i, (sy, ey) in enumerate(idxs_height):\n",
    "        for j, (sx, ex) in enumerate(idxs_width):\n",
    "            images[i, j] = image[sy:ey, sx:ex]\n",
    "    return images\n",
    "\n",
    "def unslice_images(images, size, idxs_height, idxs_width, combine_func=lambda x: np.mean(x, axis=0)):\n",
    "    image = np.full((size), np.nan)\n",
    "    for i, (sy, ey) in enumerate(idxs_height):\n",
    "        for j, (sx, ex) in enumerate(idxs_width):\n",
    "            slice = image[sy:ey, sx:ex]\n",
    "            slice[np.isnan(slice)] = images[i, j, np.isnan(slice)]\n",
    "            slice[~np.isnan(slice)] = combine_func((slice[~np.isnan(slice)], images[i, j, ~np.isnan(slice)]))        \n",
    "    return image\n",
    "\n",
    "def unslice_images(images, size, idxs_height, idxs_width, combine_func=lambda x: torch.mean(x, axis=0)):\n",
    "    image = torch.full((size), torch.nan)\n",
    "    for i, (sy, ey) in enumerate(idxs_height):\n",
    "        for j, (sx, ex) in enumerate(idxs_width):\n",
    "            slice = image[sy:ey, sx:ex]\n",
    "            slice[torch.isnan(slice)] = images[i, j, torch.isnan(slice)]\n",
    "            slice[~torch.isnan(slice)] = combine_func((slice[~torch.isnan(slice)], images[i, j, ~torch.isnan(slice)]))        \n",
    "    return image\n",
    "# unslice_images(slices, image.shape, idxs_height, idxs_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dir):\n",
    "    idx_dict = {\n",
    "        'train': [\n",
    "            34, 101, 114, 82, 123, 57, 22, 15, 137, 83, 99, 72, 47,\n",
    "            36, 96, 46, 120, 60, 19, 79, 58, 134, 39, 102, 126, 94,\n",
    "            7, 106, 2, 40, 70, 52, 104, 12, 119, 76, 108, 90, 147,\n",
    "            143, 43, 140, 142, 88, 93, 4, 51, 16, 121, 74, 64, 77,\n",
    "            98, 107, 56, 13, 92, 3, 141, 136, 146, 78, 91, 35, 124,\n",
    "            63, 130, 84, 17, 80, 25, 118, 6, 113, 117, 67, 100, 54,\n",
    "            103, 95, 37, 23, 32, 30, 42, 144, 75, 38, 50, 31, 66,\n",
    "            131, 68, 97, 85, 44, 69, 33, 5, 138, 49, 14, 128, 24,\n",
    "            11, 89, 135, 10, 29, 116, 65, 18, 125, 20, 26, 111, 73,\n",
    "            48, 59, 139],\n",
    "        'validation': [86, 21, 55, 61, 45, 81, 105, 149, 27, 132, 28, 129, 1, 53, 133],\n",
    "        'test': [115, 109, 87, 112, 8, 9, 122, 41, 148, 110, 145, 71, 150, 127, 0, 62]\n",
    "    }\n",
    "\n",
    "    image_dir = dir + '/images/'\n",
    "    mask_dir = dir +'/masks/'\n",
    "\n",
    "    image_names = sorted([image for image in listdir(image_dir) if image.endswith('.png')])\n",
    "    \n",
    "    train_names = [image_names[idx] for idx in idx_dict['train']]\n",
    "    validation_names = [image_names[idx] for idx in idx_dict['validation']]\n",
    "    test_names = [image_names[idx] for idx in idx_dict['test']]\n",
    "\n",
    "    name_dict = {'train': train_names, 'validation': validation_names, 'test': test_names}\n",
    "\n",
    "    return name_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name_dict = split_data(raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't assign a numpy.ndarray to a torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(image_slices\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m     11\u001b[0m         \u001b[39massert\u001b[39;00m image_slices[i,j]\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m slice_size \u001b[39m+\u001b[39m (\u001b[39m3\u001b[39m,), \u001b[39m\"\u001b[39m\u001b[39mImage slice did not have correct dimensions\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m unsliced_image \u001b[39m=\u001b[39m unslice_images(image_slices, image\u001b[39m.\u001b[39;49mshape, idxs_height, idxs_width)\n\u001b[1;32m     14\u001b[0m \u001b[39massert\u001b[39;00m unsliced_image\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m image\u001b[39m.\u001b[39mshape, \u001b[39m\"\u001b[39m\u001b[39mUnsliced image dimensions did not match original image\u001b[39m\u001b[39m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[14], line 35\u001b[0m, in \u001b[0;36munslice_images\u001b[0;34m(images, size, idxs_height, idxs_width, combine_func)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[39mfor\u001b[39;00m j, (sx, ex) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(idxs_width):\n\u001b[1;32m     34\u001b[0m         \u001b[39mslice\u001b[39m \u001b[39m=\u001b[39m image[sy:ey, sx:ex]\n\u001b[0;32m---> 35\u001b[0m         \u001b[39mslice\u001b[39;49m[torch\u001b[39m.\u001b[39;49misnan(\u001b[39mslice\u001b[39;49m)] \u001b[39m=\u001b[39m images[i, j, torch\u001b[39m.\u001b[39misnan(\u001b[39mslice\u001b[39m)]\n\u001b[1;32m     36\u001b[0m         \u001b[39mslice\u001b[39m[\u001b[39m~\u001b[39mtorch\u001b[39m.\u001b[39misnan(\u001b[39mslice\u001b[39m)] \u001b[39m=\u001b[39m combine_func((\u001b[39mslice\u001b[39m[\u001b[39m~\u001b[39mtorch\u001b[39m.\u001b[39misnan(\u001b[39mslice\u001b[39m)], images[i, j, \u001b[39m~\u001b[39mtorch\u001b[39m.\u001b[39misnan(\u001b[39mslice\u001b[39m)]))        \n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m image\n",
      "\u001b[0;31mTypeError\u001b[0m: can't assign a numpy.ndarray to a torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "## TEST PREPROCESS\n",
    "image = torch.moveaxis(torchvision.io.read_image(raw_dir+'/images/'+name_dict['train'][0]), 0, -1)\n",
    "\n",
    "slice_size = (512, 512)\n",
    "\n",
    "idxs_height, idxs_width = get_slice_idxs(image.shape, slice_size)\n",
    "image_slices = slice_image(image, slice_size + (3,), idxs_height, idxs_width)\n",
    "\n",
    "for i in range(image_slices.shape[0]):\n",
    "    for j in range(image_slices.shape[1]):\n",
    "        assert image_slices[i,j].shape == slice_size + (3,), \"Image slice did not have correct dimensions\"\n",
    "\n",
    "unsliced_image = unslice_images(image_slices, image.shape, idxs_height, idxs_width)\n",
    "assert unsliced_image.shape == image.shape, \"Unsliced image dimensions did not match original image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc2d3b61f1e9e23e3b2650d02a265826715832c8045a8807a8a04cd462939354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
